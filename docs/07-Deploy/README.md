# üöÄ Deploy e Monitoramento

## üìñ Vis√£o Geral

Esta se√ß√£o cont√©m toda a documenta√ß√£o necess√°ria para deploy, monitoramento, performance e manuten√ß√£o do Sistema de Intranet ELO em produ√ß√£o. Aqui voc√™ encontrar√° guias completos para diferentes plataformas, estrat√©gias de monitoramento, otimiza√ß√£o de performance e procedimentos de backup/recovery.

## üéØ Objetivos

### **Para DevOps**
- ‚úÖ **Deploy Automatizado** - Pipelines CI/CD eficientes
- ‚úÖ **Monitoramento Completo** - Observabilidade em tempo real
- ‚úÖ **Performance Otimizada** - M√©tricas e alertas proativos
- ‚úÖ **Backup e Recovery** - Estrat√©gias de alta disponibilidade
- ‚úÖ **Seguran√ßa em Produ√ß√£o** - Configura√ß√µes de seguran√ßa

### **Para Desenvolvedores**
- ‚úÖ **Deploy Simplificado** - Processo padronizado
- ‚úÖ **Debugging em Produ√ß√£o** - Ferramentas de diagn√≥stico
- ‚úÖ **Performance Monitoring** - Identifica√ß√£o de gargalos
- ‚úÖ **Logs Centralizados** - Rastreamento de erros
- ‚úÖ **Rollback Seguro** - Revers√£o r√°pida de problemas

### **Para Equipe**
- ‚úÖ **Transpar√™ncia** - Status vis√≠vel de todos os deploys
- ‚úÖ **Colabora√ß√£o** - Workflows padronizados
- ‚úÖ **Qualidade** - Gates de qualidade automatizados
- ‚úÖ **Confiabilidade** - Deploy zero-downtime

## üìã Estrutura da Documenta√ß√£o

```
docs/07-Deploy/
‚îú‚îÄ‚îÄ README.md                    # Este arquivo
‚îú‚îÄ‚îÄ plataformas/                 # Plataformas de deploy
‚îÇ   ‚îú‚îÄ‚îÄ vercel.md               # Vercel (recomendado)
‚îÇ   ‚îú‚îÄ‚îÄ railway.md              # Railway PaaS
‚îÇ   ‚îú‚îÄ‚îÄ aws.md                  # AWS (ECS/EKS)
‚îÇ   ‚îî‚îÄ‚îÄ docker.md               # Docker + Kubernetes
‚îú‚îÄ‚îÄ monitoramento/               # Monitoramento e observabilidade
‚îÇ   ‚îú‚îÄ‚îÄ analytics.md            # Vercel Analytics
‚îÇ   ‚îú‚îÄ‚îÄ logging.md              # Centraliza√ß√£o de logs
‚îÇ   ‚îú‚îÄ‚îÄ alerts.md               # Sistema de alertas
‚îÇ   ‚îî‚îÄ‚îÄ health-checks.md        # Health checks
‚îú‚îÄ‚îÄ performance/                 # Performance e otimiza√ß√£o
‚îÇ   ‚îú‚îÄ‚îÄ metrics.md              # M√©tricas de performance
‚îÇ   ‚îú‚îÄ‚îÄ optimization.md         # Otimiza√ß√µes
‚îÇ   ‚îú‚îÄ‚îÄ caching.md              # Estrat√©gias de cache
‚îÇ   ‚îî‚îÄ‚îÄ scalability.md          # Escalabilidade
‚îú‚îÄ‚îÄ backup/                      # Backup e recovery
‚îÇ   ‚îú‚îÄ‚îÄ strategy.md             # Estrat√©gias de backup
‚îÇ   ‚îú‚îÄ‚îÄ procedures.md           # Procedimentos
‚îÇ   ‚îî‚îÄ‚îÄ disaster-recovery.md    # Recupera√ß√£o de desastres
‚îî‚îÄ‚îÄ seguranca/                   # Seguran√ßa em produ√ß√£o
    ‚îú‚îÄ‚îÄ headers.md              # Security headers
    ‚îú‚îÄ‚îÄ secrets.md              # Gerenciamento de secrets
    ‚îú‚îÄ‚îÄ audit.md                # Auditoria de seguran√ßa
    ‚îî‚îÄ‚îÄ compliance.md           # Conformidade
```

## üöÄ In√≠cio R√°pido

### **Deploy B√°sico com Vercel**
```bash
# 1. Instalar Vercel CLI
npm i -g vercel

# 2. Login
vercel login

# 3. Configurar projeto
vercel link

# 4. Deploy para produ√ß√£o
vercel --prod
```

### **Monitoramento B√°sico**
```typescript
// src/lib/monitoring.ts
import { inject } from '@vercel/analytics'

export function initMonitoring() {
  // Analytics
  inject()

  // Error tracking
  initErrorTracking()

  // Performance monitoring
  initPerformanceMonitoring()
}
```

### **Health Check**
```typescript
// src/app/api/health/route.ts
export async function GET() {
  const health = await checkSystemHealth()

  return Response.json({
    status: health.status,
    timestamp: new Date().toISOString(),
    checks: health.checks,
  })
}
```

## üèóÔ∏è Estrat√©gia de Deploy

### **Plataformas Suportadas**
```typescript
export const DEPLOY_PLATFORMS = {
  VERCEL: {
    name: 'Vercel',
    type: 'Serverless',
    recommended: true,
    features: ['CDN Global', 'Auto-scaling', 'Analytics', 'Edge Functions'],
    cost: '$$$',
    complexity: 'Baixa',
  },
  RAILWAY: {
    name: 'Railway',
    type: 'PaaS',
    recommended: true,
    features: ['PostgreSQL', 'Redis', 'Auto-scaling', 'Logs'],
    cost: '$$',
    complexity: 'Baixa',
  },
  AWS: {
    name: 'AWS',
    type: 'Cloud',
    recommended: false,
    features: ['Alta escalabilidade', 'Controle total', 'Enterprise'],
    cost: '$$$$',
    complexity: 'Alta',
  },
  DOCKER: {
    name: 'Docker + K8s',
    type: 'Container',
    recommended: false,
    features: ['Portabilidade', 'Orquestra√ß√£o', 'CI/CD'],
    cost: '$$',
    complexity: 'M√©dia',
  },
} as const
```

### **Estrat√©gia Recomendada**
```typescript
// Configura√ß√£o recomendada para produ√ß√£o
export const PRODUCTION_CONFIG = {
  platform: 'VERCEL',
  database: 'PostgreSQL',
  cache: 'Redis',
  cdn: 'Vercel Edge Network',
  monitoring: 'Vercel Analytics + Sentry',
  backup: 'Database automated + File storage',
}
```

### **Tipos de Deploy**
```typescript
export const DEPLOY_TYPES = {
  STATIC: 'Static Site Generation',
  SERVERLESS: 'Serverless Functions (Recomendado)',
  CONTAINER: 'Docker Container',
  HYBRID: 'SSR + Static Pages',
} as const
```

## üìä Monitoramento e Observabilidade

### **M√©tricas Principais**
```typescript
// src/lib/metrics.ts
export class MetricsCollector {
  static async collectMetrics() {
    const [
      responseTime,
      errorRate,
      throughput,
      resourceUsage,
    ] = await Promise.all([
      this.getResponseTime(),
      this.getErrorRate(),
      this.getThroughput(),
      this.getResourceUsage(),
    ])

    return {
      responseTime,
      errorRate,
      throughput,
      resourceUsage,
      timestamp: new Date().toISOString(),
    }
  }

  static async getResponseTime() {
    // Measure API response times
    const start = Date.now()
    await fetch('/api/health')
    return Date.now() - start
  }

  static async getErrorRate() {
    // Calculate error rate from logs
    const errors = await getErrorCount()
    const total = await getTotalRequests()
    return (errors / total) * 100
  }

  static async getThroughput() {
    // Requests per second
    return await getRequestsPerSecond()
  }

  static async getResourceUsage() {
    return {
      cpu: process.cpuUsage(),
      memory: process.memoryUsage(),
      disk: await getDiskUsage(),
    }
  }
}
```

### **Sistema de Alertas**
```typescript
// src/lib/alerts.ts
export class AlertSystem {
  static async checkThresholds() {
    const metrics = await MetricsCollector.collectMetrics()
    const alerts = []

    // Response time alert
    if (metrics.responseTime > 2000) {
      alerts.push({
        level: 'WARNING',
        type: 'PERFORMANCE',
        message: 'Response time is too high',
        value: metrics.responseTime,
        threshold: 2000,
      })
    }

    // Error rate alert
    if (metrics.errorRate > 5) {
      alerts.push({
        level: 'CRITICAL',
        type: 'ERROR',
        message: 'Error rate is too high',
        value: metrics.errorRate,
        threshold: 5,
      })
    }

    // CPU usage alert
    if (metrics.resourceUsage.cpu > 80) {
      alerts.push({
        level: 'WARNING',
        type: 'RESOURCE',
        message: 'CPU usage is high',
        value: metrics.resourceUsage.cpu,
        threshold: 80,
      })
    }

    // Send alerts
    for (const alert of alerts) {
      await this.sendAlert(alert)
    }

    return alerts
  }

  static async sendAlert(alert: Alert) {
    // Send to Slack
    await fetch(process.env.SLACK_WEBHOOK_URL!, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        text: `${alert.level}: ${alert.message}`,
        fields: [{
          title: 'Valor',
          value: alert.value.toString(),
        }, {
          title: 'Limite',
          value: alert.threshold.toString(),
        }],
      }),
    })

    // Send to email
    await sendEmailAlert(alert)

    // Log alert
    await logAlert(alert)
  }
}
```

### **Health Checks**
```typescript
// src/app/api/health/route.ts
import { NextResponse } from 'next/server'

export async function GET() {
  try {
    const health = await performHealthCheck()

    return NextResponse.json({
      status: health.status,
      timestamp: new Date().toISOString(),
      version: process.env.npm_package_version,
      uptime: process.uptime(),
      checks: health.checks,
    })
  } catch (error) {
    return NextResponse.json(
      {
        status: 'unhealthy',
        timestamp: new Date().toISOString(),
        error: error instanceof Error ? error.message : 'Unknown error',
      },
      { status: 500 }
    )
  }
}

// src/lib/health-check.ts
export async function performHealthCheck() {
  const checks = {
    database: await checkDatabase(),
    redis: await checkRedis(),
    external: await checkExternalServices(),
    filesystem: await checkFileSystem(),
  }

  const status = Object.values(checks).every(check => check.status === 'healthy')
    ? 'healthy'
    : 'unhealthy'

  return { status, checks }
}

async function checkDatabase() {
  try {
    await prisma.$connect()
    await prisma.$disconnect()
    return { status: 'healthy' }
  } catch (error) {
    return {
      status: 'unhealthy',
      error: error instanceof Error ? error.message : 'Database error'
    }
  }
}

async function checkRedis() {
  try {
    const redis = new Redis(process.env.REDIS_URL!)
    await redis.ping()
    return { status: 'healthy' }
  } catch (error) {
    return {
      status: 'unhealthy',
      error: error instanceof Error ? error.message : 'Redis error'
    }
  }
}
```

## ‚ö° Performance e Otimiza√ß√£o

### **M√©tricas de Performance**
```typescript
// src/lib/performance.ts
export class PerformanceMonitor {
  static async measurePageLoad() {
    if (typeof window === 'undefined') return null

    const navigation = performance.getEntriesByType('navigation')[0] as PerformanceNavigationTiming
    const paint = performance.getEntriesByType('paint')

    return {
      domContentLoaded: navigation.domContentLoadedEventEnd - navigation.domContentLoadedEventStart,
      loadComplete: navigation.loadEventEnd - navigation.loadEventStart,
      firstPaint: paint.find(entry => entry.name === 'first-paint')?.startTime,
      firstContentfulPaint: paint.find(entry => entry.name === 'first-contentful-paint')?.startTime,
    }
  }

  static async measureAPICalls() {
    const observer = new PerformanceObserver((list) => {
      for (const entry of list.getEntries()) {
        if (entry.name.includes('/api/')) {
          console.log(`API Call: ${entry.name} - ${entry.duration}ms`)
        }
      }
    })

    observer.observe({ entryTypes: ['measure'] })
  }

  static async measureDatabaseQueries() {
    const queries = await prisma.$queryRaw`
      SELECT query, calls, total_time, mean_time, rows
      FROM pg_stat_statements
      ORDER BY mean_time DESC
      LIMIT 10
    `

    return queries
  }
}
```

### **Otimiza√ß√£o de Bundle**
```javascript
// next.config.js - Bundle optimization
/** @type {import('next').NextConfig} */
const nextConfig = {
  // Bundle analysis
  webpack: (config, { dev, isServer }) => {
    if (!dev && !isServer) {
      // Bundle analyzer
      const { BundleAnalyzerPlugin } = require('webpack-bundle-analyzer')
      config.plugins.push(
        new BundleAnalyzerPlugin({
          analyzerMode: 'static',
          reportFilename: './analyze/client.html',
          openAnalyzer: false,
        })
      )
    }

    return config
  },

  // Code splitting
  experimental: {
    optimizePackageImports: ['@radix-ui/react-icons', 'lucide-react'],
    optimizeCss: true,
  },

  // Compression
  compress: true,

  // Image optimization
  images: {
    formats: ['image/webp', 'image/avif'],
    deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840],
  },
}

module.exports = nextConfig
```

### **Cache Strategy**
```typescript
// src/lib/cache.ts
export class CacheManager {
  private redis: Redis

  constructor() {
    this.redis = new Redis(process.env.REDIS_URL!)
  }

  async get<T>(key: string): Promise<T | null> {
    try {
      const data = await this.redis.get(key)
      return data ? JSON.parse(data) : null
    } catch (error) {
      console.error('Cache get error:', error)
      return null
    }
  }

  async set(key: string, data: any, ttl: number = 3600): Promise<void> {
    try {
      await this.redis.setex(key, ttl, JSON.stringify(data))
    } catch (error) {
      console.error('Cache set error:', error)
    }
  }

  async invalidate(pattern: string): Promise<void> {
    try {
      const keys = await this.redis.keys(pattern)
      if (keys.length > 0) {
        await this.redis.del(...keys)
      }
    } catch (error) {
      console.error('Cache invalidate error:', error)
    }
  }

  // Cache user data
  async getUserData(userId: string) {
    const cacheKey = `user:${userId}`
    let userData = await this.get(cacheKey)

    if (!userData) {
      userData = await prisma.user.findUnique({
        where: { id: userId },
        include: {
          bookings: true,
          orders: true,
        },
      })

      if (userData) {
        await this.set(cacheKey, userData, 1800) // 30 minutes
      }
    }

    return userData
  }

  // Cache API responses
  async cacheAPIResponse(endpoint: string, data: any, ttl: number = 300) {
    const cacheKey = `api:${endpoint}`
    await this.set(cacheKey, data, ttl)
  }
}

// Usage in API routes
export async function GET() {
  const cache = new CacheManager()
  const cacheKey = 'dashboard:metrics'

  let metrics = await cache.get(cacheKey)
  if (!metrics) {
    metrics = await generateMetrics()
    await cache.set(cacheKey, metrics, 300) // 5 minutes
  }

  return Response.json(metrics)
}
```

### **Database Optimization**
```sql
-- Performance optimizations for PostgreSQL

-- 1. Create indexes for frequently queried columns
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_enterprise ON users(enterprise);
CREATE INDEX idx_bookings_user_id_start_time ON bookings(user_id, start_time);
CREATE INDEX idx_orders_user_id_created_at ON orders(user_id, created_at);

-- 2. Optimize slow queries
EXPLAIN ANALYZE
SELECT u.*, COUNT(b.id) as booking_count
FROM users u
LEFT JOIN bookings b ON u.id = b.user_id
WHERE u.created_at > '2024-01-01'
GROUP BY u.id;

-- 3. Partition large tables (if needed)
CREATE TABLE bookings_2024 PARTITION OF bookings
    FOR VALUES FROM ('2024-01-01') TO ('2025-01-01');

-- 4. Vacuum and analyze regularly
VACUUM ANALYZE users;
VACUUM ANALYZE bookings;

-- 5. Monitor query performance
SELECT query, calls, total_time, mean_time
FROM pg_stat_statements
ORDER BY mean_time DESC
LIMIT 10;
```

## üìã Estrat√©gia de Backup

### **Database Backup**
```bash
# Automated database backup script
#!/bin/bash

# Configuration
DB_NAME="elo_prod"
DB_USER="elo_user"
BACKUP_DIR="/backups/database"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="${BACKUP_DIR}/${DB_NAME}_${TIMESTAMP}.sql"

# Create backup directory
mkdir -p $BACKUP_DIR

# Create database backup
pg_dump -U $DB_USER -h localhost -d $DB_NAME \
  -F c -b -v -f $BACKUP_FILE \
  --exclude-table-data=audit_logs \
  --exclude-table-data=system_logs

# Compress backup
gzip $BACKUP_FILE

# Upload to cloud storage
aws s3 cp "${BACKUP_FILE}.gz" s3://elo-backups/database/

# Clean old backups (keep last 30 days)
find $BACKUP_DIR -name "*.gz" -type f -mtime +30 -delete

# Log backup completion
echo "Database backup completed: ${BACKUP_FILE}.gz" >> /var/log/backup.log
```

### **File Backup**
```bash
# File system backup script
#!/bin/bash

# Configuration
UPLOAD_DIR="/app/uploads"
BACKUP_DIR="/backups/uploads"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")

# Create incremental backup
rsync -av --delete --link-dest=$BACKUP_DIR/latest \
  $UPLOAD_DIR $BACKUP_DIR/$TIMESTAMP/

# Update latest symlink
rm -f $BACKUP_DIR/latest
ln -s $TIMESTAMP $BACKUP_DIR/latest

# Compress backup
tar -czf "${BACKUP_DIR}/${TIMESTAMP}.tar.gz" \
  -C $BACKUP_DIR $TIMESTAMP

# Upload to cloud
aws s3 cp "${BACKUP_DIR}/${TIMESTAMP}.tar.gz" \
  s3://elo-backups/uploads/

# Clean old backups
find $BACKUP_DIR -name "*.tar.gz" -type f -mtime +7 -delete
```

### **Configuration Backup**
```typescript
// src/lib/backup-config.ts
export class ConfigBackupManager {
  static async createConfigBackup() {
    const config = {
      environment: {
        NODE_ENV: process.env.NODE_ENV,
        DATABASE_URL: this.maskDatabaseUrl(process.env.DATABASE_URL),
        REDIS_URL: this.maskRedisUrl(process.env.REDIS_URL),
      },
      features: {
        analytics: process.env.FEATURE_ADVANCED_ANALYTICS,
        notifications: process.env.FEATURE_PUSH_NOTIFICATIONS,
      },
      limits: {
        maxFileSize: process.env.MAX_FILE_SIZE,
        rateLimit: process.env.RATE_LIMIT,
      },
      integrations: {
        clerk: process.env.NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY ? 'configured' : 'not configured',
        uploadthing: process.env.UPLOADTHING_APP_ID ? 'configured' : 'not configured',
      },
      timestamp: new Date().toISOString(),
    }

    await this.saveToStorage('config-backup', JSON.stringify(config, null, 2))
    await this.saveToStorage('env-template', this.createEnvTemplate())
  }

  private static maskDatabaseUrl(url?: string) {
    if (!url) return undefined
    return url.replace(/\/\/.*@/, '//***:***@')
  }

  private static maskRedisUrl(url?: string) {
    if (!url) return undefined
    return url.replace(/\/\/.*@/, '//***:***@')
  }

  private static createEnvTemplate() {
    return `# Environment Variables Template
# Copy this file to .env.local and fill with actual values

# Database
DATABASE_URL="postgresql://username:password@localhost:5432/elo_db"

# Redis (Optional)
REDIS_URL="redis://username:password@localhost:6379"

# Authentication
NEXTAUTH_SECRET="your-secret-key-here"
NEXTAUTH_URL="http://localhost:3000"

# Clerk Authentication
NEXT_PUBLIC_CLERK_PUBLISHABLE_KEY="pk_test_..."
CLERK_SECRET_KEY="sk_test_..."

# File Upload
UPLOADTHING_SECRET="sk_live_..."
UPLOADTHING_APP_ID="your-app-id"

# Email
SMTP_HOST="smtp.gmail.com"
SMTP_PORT="587"
SMTP_USER="your-email@gmail.com"
SMTP_PASS="your-app-password"

# Analytics
VERCEL_ANALYTICS_ID="your-analytics-id"

# Security
ENCRYPTION_KEY="32-character-encryption-key"

# Feature Flags
FEATURE_ADVANCED_ANALYTICS="false"
FEATURE_PUSH_NOTIFICATIONS="false"
`
  }
}
```

## üîí Seguran√ßa em Produ√ß√£o

### **Security Headers**
```typescript
// src/middleware.ts
import { NextResponse } from 'next/server'
import type { NextRequest } from 'next/server'

export function middleware(request: NextRequest) {
  const response = NextResponse.next()

  // Security Headers
  response.headers.set('X-Frame-Options', 'DENY')
  response.headers.set('X-Content-Type-Options', 'nosniff')
  response.headers.set('Referrer-Policy', 'origin-when-cross-origin')
  response.headers.set('Permissions-Policy', 'camera=(), microphone=(), geolocation=()')

  // Content Security Policy
  response.headers.set(
    'Content-Security-Policy',
    [
      "default-src 'self'",
      "script-src 'self' 'unsafe-inline' 'unsafe-eval' https://*.clerk.dev",
      "style-src 'self' 'unsafe-inline'",
      "img-src 'self' data: https: blob:",
      "font-src 'self'",
      "connect-src 'self' https://*.clerk.dev https://*.uploadthing.com",
      "frame-src 'self' https://*.clerk.dev",
    ].join('; ')
  )

  // HSTS (HTTP Strict Transport Security)
  response.headers.set('Strict-Transport-Security', 'max-age=31536000; includeSubDomains')

  return response
}

export const config = {
  matcher: ['/((?!api|_next/static|_next/image|favicon.ico).*)'],
}
```

### **Rate Limiting**
```typescript
// src/lib/rate-limit.ts
import { Ratelimit } from '@upstash/ratelimit'
import { Redis } from '@upstash/redis'

const redis = new Redis({
  url: process.env.REDIS_URL!,
  token: process.env.REDIS_TOKEN!,
})

// Rate limiters for different endpoints
export const authRateLimit = new Ratelimit({
  redis,
  limiter: Ratelimit.slidingWindow(5, '1 m'), // 5 requests per minute
  analytics: true,
})

export const apiRateLimit = new Ratelimit({
  redis,
  limiter: Ratelimit.slidingWindow(100, '1 m'), // 100 requests per minute
  analytics: true,
})

export const uploadRateLimit = new Ratelimit({
  redis,
  limiter: Ratelimit.slidingWindow(10, '1 h'), // 10 uploads per hour
  analytics: true,
})

// Middleware to apply rate limiting
export async function rateLimitMiddleware(
  request: NextRequest,
  rateLimiter: Ratelimit
) {
  const ip = request.ip ?? '127.0.0.1'

  try {
    const { success } = await rateLimiter.limit(ip)

    if (!success) {
      return new Response('Too many requests', {
        status: 429,
        headers: {
          'Retry-After': '60',
        },
      })
    }

    return null
  } catch (error) {
    console.error('Rate limit error:', error)
    return null
  }
}
```

### **Data Sanitization**
```typescript
// src/lib/sanitizer.ts
import DOMPurify from 'dompurify'

export class DataSanitizer {
  static sanitizeHtml(html: string): string {
    return DOMPurify.sanitize(html, {
      ALLOWED_TAGS: [
        'p', 'br', 'strong', 'em', 'a', 'ul', 'ol', 'li',
        'h1', 'h2', 'h3', 'h4', 'h5', 'h6',
      ],
      ALLOWED_ATTR: ['href', 'target', 'rel'],
      ALLOW_DATA_ATTR: false,
      ALLOW_UNKNOWN_PROTOCOLS: false,
    })
  }

  static sanitizeInput(input: string): string {
    return input
      .replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, '')
      .replace(/javascript:/gi, '')
      .replace(/on\w+=/gi, '')
      .replace(/[<>'"&]/g, (match) => {
        const escapeMap: Record<string, string> = {
          '<': '&lt;',
          '>': '&gt;',
          '"': '&quot;',
          "'": '&#x27;',
          '&': '&amp;',
        }
        return escapeMap[match]
      })
      .trim()
  }

  static sanitizeFilename(filename: string): string {
    return filename
      .replace(/[^a-zA-Z0-9._-]/g, '_')
      .replace(/_{2,}/g, '_')
      .replace(/^_+|_+$/g, '')
      .substring(0, 255)
  }

  static validateEmail(email: string): boolean {
    const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/
    return emailRegex.test(email) && email.length <= 254
  }

  static validatePassword(password: string): boolean {
    // At least 8 characters, 1 uppercase, 1 lowercase, 1 number
    const passwordRegex = /^(?=.*[a-z])(?=.*[A-Z])(?=.*\d)[a-zA-Z\d@$!%*?&]{8,}$/
    return passwordRegex.test(password)
  }
}
```

## üìã Checklist de Deploy

### **Pre-Deploy**
- [ ] Testes passando em CI/CD
- [ ] Build funcionando localmente
- [ ] Vari√°veis de ambiente configuradas
- [ ] Migra√ß√µes de banco testadas
- [ ] Documenta√ß√£o atualizada
- [ ] Plano de rollback definido
- [ ] Backup recente realizado

### **Durante Deploy**
- [ ] Monitorar logs em tempo real
- [ ] Verificar health checks
- [ ] Testar funcionalidades cr√≠ticas
- [ ] Monitorar performance
- [ ] Preparar rollback se necess√°rio

### **P√≥s-Deploy**
- [ ] Executar smoke tests
- [ ] Verificar analytics
- [ ] Monitorar erros
- [ ] Atualizar documenta√ß√£o
- [ ] Notificar stakeholders

### **Monitoramento Cont√≠nuo**
- [ ] Alertas configurados
- [ ] Logs centralizados
- [ ] M√©tricas de performance
- [ ] Backup autom√°tico
- [ ] Auditoria de seguran√ßa

### **Performance**
- [ ] Core Web Vitals monitorados
- [ ] Bundle size otimizado
- [ ] Cache configurado
- [ ] Database queries otimizadas
- [ ] CDN ativo

### **Seguran√ßa**
- [ ] Headers de seguran√ßa configurados
- [ ] Rate limiting ativo
- [ ] SSL/TLS configurado
- [ ] Secrets seguros
- [ ] Auditoria de seguran√ßa

---

**üìÖ √öltima atualiza√ß√£o**: Mar√ßo 2025
**üë• Mantido por**: Equipe de DevOps
